# Copyright 2024 Google LLC.
# (Tu licencia aquí)

# ===============================================================
# SECCIÓN 1: CONFIGURACIÓN DEL EXPERIMENTO Y DATOS
# ===============================================================

# --- Configuración General del Experimento ---
seed: 42
do_train: true
do_test: false # Cambia a true cuando quieras evaluar un modelo ya entrenado
task: finetune
experiment_name: mi_experimento_finetune_v1
output_dir: ./outputs/

# --- Configuración del Dataset (¡La parte más importante para ti!) ---
dataset_name: "custom" # Activa nuestro código en main.py
data_dir: "/content/lanistr/"   # Ruta a la carpeta que contiene tu CSV
category: "multi_dataset"   # Nombre de tu CSV (sin la extensión .csv)

# --- Definición del Esquema de Datos ---
# Aquí defines la estructura de tu CSV. ¡Máxima flexibilidad!
data_schema:
  # Unimos las 4 fases de la conversación para un contexto completo
  text_cols:
    - 'apertura'
    - 'interaccion'
    - 'resultado'
    - 'cierre'

  # Usamos todas las características numéricas y de sentimiento
  numeric_cols:
    - 'num_word_text'
    - 'count_dialogue_cliente'
    - 'num_word_text_captador'
    - 'num_word_text_cliente'
    - 'word_per_dialogue_operador'
    - 'proportion_dialogue_captador'

  # Tu dataset no tiene columnas categóricas, lo cual es normal.
  # Dejamos la lista vacía.
  categorical_cols:
    - 'sentiment_text_POS'
    - 'sentiment_cliente_POS'
    - 'sentiment_captador_POS'

  # La columna 'result' es claramente el objetivo a predecir
  target_col: 'result'

# --- Configuración de Modalidades ---
# Desactivamos la modalidad de imagen
image: false
text: true
time: false
tab: true

finetune_initialize_from: pretrain

# ===============================================================
# SECCIÓN 2: HIPERPARÁMETROS DEL MODELO Y ENTRENAMIENTO
# (Puedes copiar y ajustar estos valores desde los .yaml de Amazon)
# ===============================================================

# --- Entrenamiento ---
train_batch_size: 32
eval_batch_size: 64
num_classes: 2 # Ajusta al número de clases de tu 'target_col'
perf_metric: accuracy # O 'auc', etc.

# --- Optimizador y Scheduler ---
scheduler:
  num_epochs: 50
  warmup_epochs: 5
optimizer:
  learning_rate: 1e-4
  weight_decay: 0.1

# --- Arquitectura del Modelo ---
# Como image=false, la sección del "image_encoder" es ignorada por el modelo,
# así que la podemos omitir para mayor claridad.

# simsiam pretraining projector and predictor
projection_type: SimSiam
predictor_hidden_dim: 512
predictor_out_dim: 2048

# unimodal encoders projection dim
projection_dim: 768

# classifier head
classifier_hidden_dim: 768

# text encoder
tokenizer_name_or_path: bert-base-uncased
text_encoder_name: bert-base-uncased
text_encoder_pretrained: true
text_encoder_trainable: false
text_proj_trainable: true
text_embedding_dim: 768
max_token_length: 512
mlm_probability: 0.15

# tabular encoder
tabular_encoder_name: tabnet
tabular_encoder_trainable: false
tabular_proj_trainable: true
tabular_output_dim: 768
tabular_embedding_dim: 64
tabular_pretraining_ratio: 0.15
tabular_cat_emb_dim: 3
tabular_mask_type: sparsemax
tabular_n_d: 64
tabular_n_a: 64

# --- AÑADE ESTE BLOQUE COMPLETO ---
# image encoder (parámetros fantasma para satisfacer al constructor)
# El modelo NO usará imágenes porque 'image: false' sigue activo.
image_encoder_name: google/vit-base-patch16-224
image_encoder_pretrained: false  # False para no descargar pesos innecesarios
image_encoder_trainable: false
image_proj_trainable: false
image_embedding_dim: 768

# Multimodal Fusion
mm_encoder_trainable: true
mm_hidden_dim: 2048
mm_output_dim: 2048

# --- Paralelismo ---
# Configuración para una sola GPU
multiprocessing_distributed: false
ngpus_per_node: 1
world_size: 1